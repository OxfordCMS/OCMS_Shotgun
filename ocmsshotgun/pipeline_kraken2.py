"""===========================
pipeline_kraken2.py
===========================

Overview
========

This pipeline takes raw fastq files and taxonomically classifies them. It also estimates abundance.
files :file:``pipeline.yml` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use cgat pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   ocms_shotgun kraken2 config

Input files
-----------

fastq files that are in the format .fastq.1.gz and .fastq.2.gz.

Dependencies
------------
kraken2
bracken

module load Kraken2/2.0.9-beta-gompi-2020a-Perl-5.30.2
module load Bracken/2.6.0-GCCcore-9.3.0

Pipeline output
===============


Glossary
========

.. glossary::


Code
====

"""
import sys
import os
import re
import glob
import yaml
from pathlib import Path
from ruffus import *
from cgatcore import pipeline as P
import ocmsshotgun.modules.Kraken2 as K
import ocmsshotgun.modules.Utility as utility
PARAMS = P.get_parameters(["pipeline.yml"])

# check files to be processed
indir = PARAMS.get('general_input.dir', 'input.dir')
FASTQ1 = utility.check_input(indir)

#get all files within the directory to process
SEQUENCEFILES = ("*.fastq.1.gz")

SEQUENCEFILES_REGEX = regex(
    r"(\S+).(fastq.1.gz)")

########################################################
########################################################
########################################################
# Run kraken2 on raw reads
########################################################
########################################################
########################################################

@follows(mkdir("kraken2.dir"))
@transform(SEQUENCEFILES, 
           SEQUENCEFILES_REGEX, 
           r"kraken2.dir/\1.k2.report.tsv")
def runKraken2(infile, outfile):
    '''classify reads with kraken2
    '''
    statement  = K.kraken2(infile, outfile, **PARAMS).buildStatement()
    P.run(statement,
          job_threads = PARAMS["kraken2_job_threads"],
          job_memory = PARAMS["kraken2_job_mem"],
          job_options = PARAMS.get('kraken2_job_options',''))

########################################################
########################################################
########################################################
# bracken abundance
########################################################
########################################################
########################################################
# use output of classifyReadsWithKraken2 to generate list 
# of bracken inputs and outputs for every taxononmic level    
                                
@follows(runKraken2)
@follows(mkdir("bracken.dir"))
@files(K.generate_parallel_params)
def runBracken(infile, outfile):
    '''
    convert read classifications into abundance with Bracken
    '''
    print('=============================================================')
    print(infile)
    print(outfile)
    statement = K.bracken(infile, outfile, **PARAMS).buildStatement()

    P.run(statement,
          job_threads = PARAMS["bracken_job_threads"],
          job_memory = PARAMS["bracken_job_mem"],
          job_options = PARAMS.get('bracken_job_options',''))    

# check all backen at all taxonomic levels has been run
@follows(runBracken)
@merge(K.files_to_check(), "bracken.dir/.sentinel.check")
def checkBrackenLevels(expected_files, outfile):
    
   K.check_bracken_levels(expected_files, outfile)

########################################################
########################################################
########################################################
# merge abundance files
########################################################
########################################################
########################################################
@follows(checkBrackenLevels)
@collate(runBracken, regex(r"bracken.dir/.*abundance\.(.+).tsv"),r"bracken.dir/merged_abundances.\1.tsv")
def mergeBracken(infiles, outfile):
    '''
    merge sample results from bracken
    '''
    level = P.snip(os.path.basename(outfile), ".tsv")
    level = level.split(".")[-1]

    sample_names = [P.snip(os.path.basename(x), ".tsv") for x in glob.glob("bracken.dir/*.abundance.%s.tsv" % level)]
    sample_names = [P.snip(x, "." + level) for x in sample_names]
    titles = ",".join([x for x in sample_names])

    statement = '''  ocms_shotgun combine_tables
                     --glob=bracken.dir/*.abundance.%(level)s.tsv
                     --skip-titles
                     --header-names=%(titles)s
                     -m 0
                     -k 6
                     -c 1,2
                     --log=bracken.dir/merged_abundances.%(level)s.log > %(outfile)s                
                 '''
    P.run(statement)

########################################################
########################################################
########################################################
# taxonomy table
########################################################
########################################################
########################################################
@follows(mkdir("taxonomy.dir"))
@transform(mergeBracken, regex(r"bracken.dir/merged_abundances.(.*).tsv"), r"taxonomy.dir/mpa_taxonomy.\1.tsv")
def translateTaxonomy(infile, outfile):
    '''
    translate kraken2 output to mpa-style taxonomy table 
    with full taxonomic names across all levels
    '''
    taxdump = PARAMS.get("bracken_taxdump")
    job_threads = PARAMS.get("bracken_job_threads")
    job_memory = PARAMS.get("bracken_job_mem")

    statement = ''' ocms_shotgun bracken2mpataxonomy
                   --mergedbracken %(infile)s
                   --translatedout %(outfile)s
                   --taxdatadir %(taxdump)s;
                '''
    P.run(statement)

########################################################
########################################################
########################################################
# Add taxonomy to counts tables
########################################################
########################################################
########################################################
@follows(mkdir("counts.dir"))
@transform(translateTaxonomy,
           regex("taxonomy.dir/mpa_taxonomy\.(\S+).tsv"),
           r"counts.dir/\1_counts.tsv")
def addTaxonomyToCounts(infile, outfile):
    '''
    add taxonomy information to the bracken counts tables
    '''
    taxonomy_file = infile
    level = os.path.basename(infile).split(".")[1]
    counts_file = [
        x for x in glob.glob("bracken.dir/merged_abundances*.tsv") if level in x][0]
    statement = '''ocms_shotgun add_taxonomy
                   -c %(counts_file)s
                   -t %(taxonomy_file)s
                   --log=counts.dir/add_taxonomy_%(level)s.log
                   > %(outfile)s
                '''
    P.run(statement)



# ---------------------------------------------------
# Generic pipeline tasks
@follows(addTaxonomyToCounts)
def full():
    pass


def main(argv=None): 
    if argv is None: 
        argv = sys.argv 
    P.main(argv)


if __name__ == "__main__": 
    sys.exit(P.main(sys.argv))
