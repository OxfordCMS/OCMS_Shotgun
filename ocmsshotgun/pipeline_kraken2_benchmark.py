"""===========================
pipeline_kraken2_benchmark.py
==============================

Overview
========

This pipeline takes raw fastq files and taxonomically classifies them. It also estimates abundance.
files :file:``pipeline.yml` and :file:`conf.py`.

The pipeline tests a range of --confidence values (0-1) to be run on community mock standards to determine thresholds.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use cgat pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   ocms_shotgun kraken2_benchmark config

Input files
-----------

fastq files that are in the format .fastq.1.gz and .fastq.2.gz.

Dependencies
------------
kraken2
bracken

module load Kraken2/2.0.9-beta-gompi-2020a-Perl-5.30.2
module load Bracken/2.6.0-GCCcore-9.3.0

Pipeline output
===============


Glossary
========

.. glossary::


Code
====

"""
import sys
import os
import re
import glob
import yaml
from pathlib import Path
from ruffus import *
from cgatcore import pipeline as P
import ocmsshotgun.modules.Kraken2 as K
import ocmsshotgun.modules.Utility as utility
PARAMS = P.get_parameters(["pipeline.yml"])

# check files to be processed
FASTQ1 = utility.check_input()

#get all files within the directory to process
SEQUENCEFILES = ("*.fastq.1.gz")

SEQUENCEFILES_REGEX = regex(
    r"(\S+)/(\S+).fastq.1.gz")

########################################################
########################################################
########################################################
# Create directories and inputs for kraken2 task
########################################################
########################################################
########################################################
@follows(mkdir("confidence_00.dir"),
         mkdir("confidence_01.dir"),
         mkdir("confidence_02.dir"),
         mkdir("confidence_03.dir"),
         mkdir("confidence_04.dir"),
         mkdir("confidence_05.dir"),
         mkdir("confidence_06.dir"),
         mkdir("confidence_07.dir"),
         mkdir("confidence_08.dir"),
         mkdir("confidence_09.dir"),
         mkdir("confidence_10.dir"))

@split(SEQUENCEFILES, "confidence_*.dir/*.fastq.1.gz")
def linkInputs(infiles, outfiles):
    '''
    link the original input files to new
    directories to run at each confidence 
    level
    '''
    without_cluster = True
    ranges = ["0" + str(i) for i in range(10)] + ["10"]
    for i in ranges:
        outdir = "confidence_" + i + ".dir"
        for infile in infiles:
            fastq2 = P.snip(infile, ".fastq.1.gz") + ".fastq.2.gz"
            if os.path.exists(fastq2):
                fastq2 = fastq2
            else:
                fastq2 = ""
            statement = '''cd %(outdir)s;
                           ln -s ../%(infile)s %(infile)s;
                           ln -s ../%(fastq2)s %(fastq2)s;
                           cd ../''' % locals()
            P.run(statement)
                
########################################################
########################################################
########################################################
# Run kraken2 on raw reads
########################################################
########################################################
########################################################
@transform(linkInputs, 
           SEQUENCEFILES_REGEX, 
           r"\1/\2.k2.report.tsv")
def runKraken2(infile, outfile):
    '''classify reads with kraken2
    '''

    # build initial statement
    statement  = K.kraken2(infile, outfile, **PARAMS).buildStatement()

    # get the confidence parameter for the infile
    confidence = list(os.path.dirname(infile).split("_")[1].split(".")[0])
    confidence = ".".join(confidence)

    # split statement to insert the confidence parameter
    statement = statement.split(";")

    # insert confidence parameter
    statement = statement[0] + " --confidence "+confidence + " ; " + statement[1]
    
    P.run(statement,
          job_threads = PARAMS["kraken2_job_threads"],
          job_memory = PARAMS["kraken2_job_mem"],
          job_options = PARAMS.get('kraken2_job_options',''))

########################################################
########################################################
########################################################
# bracken abundance
########################################################
########################################################
########################################################
@transform(runKraken2, regex("(\S+)/(\S+).k2.report.tsv"), r"\1/\2.abundance.tsv")
def runBracken(infile, outfile):
    '''
    convert read classifications into abundance with Bracken
    '''
    # bracken parameters
    db = PARAMS["bracken_db"]
    read_len = PARAMS["bracken_read_len"]
    options = PARAMS["bracken_options"]
    infile = infile

    # get directories for results
    outdir = os.path.dirname(infile)
    prefix = os.path.basename(infile).split(".")[0]
    
    # There would need some changes to Kraken2.py to
    # use the bracken statement gen here so at the
    # moment and to avoid refactoring I have just
    # lifted the statement as only using for species-level
    # assignments
    statement = ('bracken' 
                 ' -d %(db)s'
                 ' -i %(infile)s'
                 ' -o %(outfile)s'
                 ' -w %(outdir)s/%(prefix)s.k2b.report.tsv'
                 ' -l S'
                 ' %(options)s' % locals())
    P.run(statement)

########################################################
########################################################
########################################################
# merge abundance files
########################################################
########################################################
########################################################
@merge(runBracken, "bracken_merge.sentinel")
def mergeBracken(infiles, outfile):
    '''
    merge sample results from bracken
    '''
    # merge happens per directory.
    # Should be pretty quick so not worrying about
    # making it parallel at this point
    for directory in glob.glob("confidence_[0-9]*.dir"):
        sample_names = [
            P.snip(os.path.basename(x),
                   ".tsv") for x in glob.glob("%(directory)s/*.abundance.tsv" % locals())
        ]
        
        titles = ",".join([x for x in sample_names])
        outf = os.path.join(directory, "merged_abundance.tsv")
        statement = '''  ocms_shotgun combine_tables
                        --glob=%(directory)s/*.abundance.tsv
                        --skip-titles
                        --header-names=%(titles)s
                        -m 0
                        -k 6
                        -c 1,2
                        --log=%(directory)s/merged_abundances.log > %(outf)s                
                 '''
        P.run(statement)
    os.system('''touch %(outfile)s''' % locals())

########################################################
########################################################
########################################################
# taxonomy table
########################################################
########################################################
########################################################
@follows(mergeBracken)
@transform("*/merged_abundance.tsv", regex("(\S+)/merged_abundance.tsv"), r"\1/mpa_taxonomy.tsv")
def translateTaxonomy(infile, outfile):
    '''
    translate kraken2 output to mpa-style taxonomy table 
    with full taxonomic names across all levels
    '''
    taxdump = PARAMS.get("bracken_taxdump")
    job_threads = PARAMS.get("bracken_job_threads")
    job_memory = PARAMS.get("bracken_job_mem")

    statement = ''' ocms_shotgun bracken2mpataxonomy
                   --mergedbracken %(infile)s
                   --translatedout %(outfile)s
                   --taxdatadir %(taxdump)s;
                '''
    P.run(statement)

########################################################
########################################################
########################################################
# Add taxonomy to counts tables
########################################################
########################################################
########################################################
@transform(translateTaxonomy,
           regex("(\S+).dir/mpa_taxonomy.tsv"),
           r"\1.dir/\1_species_counts.tsv")
def addTaxonomyToCounts(infile, outfile):
    '''
    add taxonomy information to the bracken counts tables
    '''
    taxonomy_file = infile
    directory = os.path.dirname(infile)
    counts_file = os.path.join(directory, "merged_abundance.tsv")

    statement = '''ocms_shotgun add_taxonomy
                   -c %(counts_file)s
                   -t %(taxonomy_file)s
                   --log=%(directory)s/add_taxonomy.log
                   > %(outfile)s
                '''
    P.run(statement)

# ---------------------------------------------------
# Generic pipeline tasks
@follows(addTaxonomyToCounts)
def full():
    pass


def main(argv=None): 
    if argv is None: 
        argv = sys.argv 
    P.main(argv)


if __name__ == "__main__": 
    sys.exit(P.main(sys.argv))
